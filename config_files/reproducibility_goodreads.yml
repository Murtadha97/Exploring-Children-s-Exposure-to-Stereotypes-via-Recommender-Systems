experiment:
  dataset: goodreads_fold2
  data_config:
#    strategy: dataset
#    dataset_path: ../Datasets/goodreads_ratings.tsv
    strategy: hierarchy
    root_folder: ../data/goodreads/splitting/
#    side_information:
#      - dataloader: ChainedKG
#        map: ../data/cat_dbpedia_movielens_1m_v030/map.tsv
#        features: ../data/cat_dbpedia_movielens_1m_v030/features.tsv
#        properties: ../data/cat_dbpedia_movielens_1m_v030/properties.conf
#  prefiltering:
#    - strategy: global_threshold
#      threshold: 4
#    - strategy: iterative_k_core
#      core: 10
  binarize: True
#  splitting:
#    save_on_disk: True
#    save_folder: ../data/goodreads/splitting/
#    test_splitting:
#      test_ratio: 0.2
#      strategy: random_subsampling
#      folds: 5
  top_k: 50
  evaluation:
    cutoffs: [10]
    simple_metrics: [nDCG, MRR, MAP, HR, Recall, Precision]
    paired_ttest: True
    wilcoxon_test: True
  gpu: 1
  external_models_path: ../../elliot/external/models/__init__.py
  models:
    RecommendationFolder:
      folder: "/data/volume_2/elliot/results/goodreads_fold2/statistical/"
#    AttributeItemKNN:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        save_recs: True
#      neighbors: [uniform, 50, 1000]
#      similarity: braycurtis
#      implicit: True
#      loader: ChainedKG
#    AttributeUserKNN:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        save_recs: True
#      neighbors: [uniform, 50, 1000]
#      similarity: braycurtis
#      implicit: True
#      loader: ChainedKG
#    MF:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: False
#        save_recs: True
#      batch_size: 1024 #[256, 512, 1024]
#      epochs: 50
#      factors: 64 #[8, 64, 128]
#      lr: 0.00034890740870303905 #[loguniform, -11.512925464970229, 0] #0.0008009007515056517
#      reg: 0.002155148212584654 #[loguniform, -11.512925464970229, -2.30258509299] #0.6522390533500544
#      m: 8 #[4,6,8]
#      early_stopping:
#        patience: 5 # int
#        monitor: nDCG@10
#        mode: auto
#        verbose: True
#        min_delta: 0.001
#    PureSVD:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        verbose: False
#        save_recs: True
#      factors: [quniform, 10, 100, 1]
#      seed: 42
#    FunkSVD:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        verbose: False
#        save_recs: True
#      epochs: 50
#      batch_size: 1024
#      factors: [quniform, 10, 100, 1]
#      lr: [loguniform, -11.512925464970229, 0] #0.00012133279517930688
#      reg_w: [loguniform, -11.512925464970229, -2.30258509299] #0.1
#      reg_b: [loguniform, -11.512925464970229, -2.30258509299] #0.001
#    PMF:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        verbose: False
#        save_recs: True
#      epochs: 50
#      batch_size: 256
#      factors: [quniform, 10, 100, 1] #98
#      lr: [loguniform, -11.512925464970229, 0] #0.00035306871380963445
#      reg: [loguniform, -11.512925464970229, -2.30258509299] #0.0025
#      gaussian_variance: 0.1
#    Random:
#      meta:
#        save_recs: True
#    external.MostPop:
#      meta:
#        verbose: False
#        save_recs: True
#    UserKNN:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        save_recs: True
#        verbose: False
#      neighbors: [ uniform, 5, 1000 ]
#      similarity: cosine
#    ItemKNN:
#      meta:
#        save_recs: True
#        verbose: False
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#      neighbors: [uniform, 5, 1000]
#      similarity: cosine
#    RP3beta:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        verbose: True
#        save_recs: True
#      neighborhood: [quniform, 5, 1000, 1]
#      alpha: [uniform, 0, 2]
#      beta: [uniform, 0, 2]
#      normalize_similarity: [True, False]
#    Slim:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        verbose: False
#        save_recs: True
#      l1_ratio: [loguniform, -11.512925464970229, 0]
#      alpha: [uniform, 10e-3, 1]
#      neighborhood: [quniform, 5, 1000, 1]
#    EASER:
#      meta:
#        verbose: True
#        save_recs: True
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#      l2_norm: [loguniform, 2.72, 16]
#    MF2020:
#      meta:
#        validation_rate: 1
#        verbose: True
#        save_recs: True
#      epochs: 256
#      factors: 32
#      lr: 0.002
#      reg: 0.005
#      m: 8
#      random_seed: 42
#    iALS:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        verbose: True
#        save_recs: True
#        validation_rate: 20
#      epochs: [uniform, 1, 500]
#      scaling: [linear, log]
#      factors: [quniform, 1, 200, 1]
#      alpha: [uniform, 10e-4, 50]
#      epsilon: [uniform, 10e-4, 10]
#      reg: [uniform, 10e-4, 10e-3]
#    BPRMF:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        verbose: False
#        save_recs: True
#      lr: [loguniform, -11.512925464970229, 0]
#      batch_size: [128, 256, 512]
#      epochs: 30 #[quniform, 30, 100, 1]
#      bias_regularization: 0
#      user_regularization: [loguniform, -11.512925464970229, -2.30258509299]
#      positive_item_regularization: [loguniform, -11.512925464970229, -2.30258509299]
#      negative_item_regularization: [loguniform, -11.512925464970229, -2.30258509299]
#      factors: [8, 16, 32, 64, 128, 256]
#    NeuMF: #from the original paper + Rendle
#      meta:
#        verbose: False
#        save_recs: True
#        validation_rate: 1
#      mf_factors: 32 #[8, 16, 32]
#      dropout: 0
#      is_mf_train: True
#      is_mlp_train: True
#      batch_size: 1024
#      epochs: 20
#      lr: 0.001 #[loguniform, -11.512925464970229, 0]
#      m: 4 #[4,6,8]
#    MultiVAE: # from original paper
#      meta:
#        save_recs: True
#      lr: 0.001 # exploration taken from TOIS
#      epochs: 15
#      batch_size: 512 #[64, 128, 512]
#      intermediate_dim: 600
#      latent_dim: 200
#      dropout_pkeep: 0.5
#      reg_lambda: 0 # exploration taken from TOIS
#    AMF:
#      meta:
#        save_recs: True
#        hyper_max_evals: 5
#        hyper_opt_alg: tpe
#        eval_perturbations: True
#        validation_rate: 1
#        verbose: False
#      epochs: 30
#      batch_size: 1024
#      factors: 22 #[quniform, 8, 32, 1] #15
#      lr: 0.0001 #[0.01, 0.001, 0.0001]
#      l_w: 0.0001
#      l_b: 0.0001
#      eps: 0.5 # [uniform, 0.1, 0.5] # Magnitude of the Perturbation
#      l_adv: 1 # Adversarial Regularization Parameters
#      adversarial_epochs: 30 #[quniform, 4, 8, 1] # Number of final epochs to be run [APR starts from (epochs - adversarial_epochs) epoch]
#      eps_iter: 0.00001 #0.0625 # 2.5 * e-test / num_steps (Iterative Perturbations)
#      nb_iter: 20
#      early_stopping:
#        patience: 5 # int
#        monitor: nDCG@10
#        mode: auto
#        verbose: False
#        min_delta: 0.001
#    ConvMF:
#      epochs: 50
#      batch_size: 64 
#      embedding_size: 64
#      lr: 0.001
#      l_w: 0.005 #[0.0001, 0.001, 0.0005,  0.1]
#      l_b: 0.0005 #[0.01, 0.001,0.0001, 0.00001]
#      cnn_channels: (1, 32, 32)
#      cnn_kernels: (2,2)
#      cnn_strides: (2,2)
#      dropout_prob: 0.3
#      meta:
#        verbose: False
#        hyper_max_evals: 10
#        hyper_opt_alg: grid
#        save_recs: True
#    DeepFM:
#      meta:
#        save_recs: True
#        verbose: False
#        hyper_max_evals: 10
#        hyper_opt_alg: grid
#      epochs: 50
#      batch_size: 512 #[512, 1024]
#      factors: 50 #[32, 25, 50]
#      lr: 0.001
#      l_w: 0.001 #[0.0001, 0.001, 0.0005,  0.1]
#      hidden_neurons: (64,32)
#      hidden_activations: ('relu','relu')



